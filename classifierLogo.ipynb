{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logo_classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcmwvHt3nrfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paCePRctnen0",
        "colab_type": "text"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfuqYL78n61K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30f5fe64-5e11-4859-f87d-817b7f0f0490"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "from keras.layers import Input\n",
        "from keras import initializers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, MaxPooling2D\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten, Activation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5XB77V4nwdx",
        "colab_type": "text"
      },
      "source": [
        "The dataset consists of a total of 300 images. 50 images of 6 classes each. We use 80% of these images for training our model and remaining 20% for testing the model. For splitting the dataset, we generate 60 random numbers in the range of 0 to 299. These numbers are used as indexs for retreiving images from the dataset which is in the form of a numpy array. Since the images are not stored sequentially in the dataset, this splits the dataset in a way that samples of all the classes are equally selected.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhHkhhu_oEL8",
        "colab_type": "code",
        "outputId": "84c24f41-399a-4bda-cd5b-b6e8ccf2fa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Club logo classification/')\n",
        "path = os.getcwd()\n",
        "\n",
        "data = np.load('data.npy')\n",
        "labels = np.load('target_labels.npy')\n",
        "\n",
        "def test_train_split(data):\n",
        "    test_samples = list(random.sample(range(0, 300), 60))\n",
        "    train_samples = []\n",
        "    for i in range(0, 300):\n",
        "        if i not in test_samples:\n",
        "            train_samples.append(i)\n",
        "    temp = []\n",
        "    for i in train_samples:\n",
        "        temp.append(data[i])\n",
        "    train_x = np.asarray(temp)\n",
        "    temp = []\n",
        "    for i in train_samples:\n",
        "        temp.append(labels[i])\n",
        "    train_y = np.asarray(temp)\n",
        "    temp = []\n",
        "    for i in test_samples:\n",
        "        temp.append(data[i])\n",
        "    test_x = np.asarray(temp)\n",
        "    temp = []\n",
        "    for i in test_samples:\n",
        "        temp.append(labels[i])\n",
        "    test_y = np.asarray(temp)\n",
        "\n",
        "    print(train_x.shape)\n",
        "    print(train_y.shape)\n",
        "    print(test_x.shape)\n",
        "    print(test_y.shape)\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "train_x, train_y, test_x, test_y = test_train_split(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 224, 224, 3)\n",
            "(240,)\n",
            "(60, 224, 224, 3)\n",
            "(60,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVKKn1YspyqM",
        "colab_type": "text"
      },
      "source": [
        "By using Transfer Learning, we can build our model on top of an exsting pre-trained model. This method is effective when we want to extract higher level features from a relatively small dataset. We use the MobileNet_v2 model pre-trained on the Imagenet dataset. We remove the fully connected layer of the model which is trained to classify 1000 classes and replace with our fully conected layer to classify  6 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH7SIbF2okCt",
        "colab_type": "code",
        "outputId": "0625b615-ed55-47a8-cf82-c441d495565d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "base_model = applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "add_model = Sequential()\n",
        "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "add_model.add(Dense(256, activation='relu'))\n",
        "add_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVSocWxJ7S_T",
        "colab_type": "text"
      },
      "source": [
        "Train the model for 25 epochs with a batch_size of 5 and 20% validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anSvTvMo6_o",
        "colab_type": "code",
        "outputId": "313011c0-0516-467d-811b-9f980b068ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "model.fit(train_x, train_y, batch_size = 5, validation_split = 0.2, epochs = 25)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 17s 89ms/step - loss: 1.2548 - acc: 0.5469 - val_loss: 0.5846 - val_acc: 0.8333\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.3749 - acc: 0.9115 - val_loss: 0.4470 - val_acc: 0.8542\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.1972 - acc: 0.9323 - val_loss: 0.4928 - val_acc: 0.8542\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0510 - acc: 0.9844 - val_loss: 0.2953 - val_acc: 0.8958\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0710 - acc: 0.9792 - val_loss: 0.3510 - val_acc: 0.8750\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0861 - acc: 0.9635 - val_loss: 0.2571 - val_acc: 0.9167\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0304 - acc: 0.9896 - val_loss: 0.2989 - val_acc: 0.8958\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0269 - acc: 0.9896 - val_loss: 0.2634 - val_acc: 0.8958\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.4657 - val_acc: 0.8750\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0127 - acc: 0.9948 - val_loss: 0.4484 - val_acc: 0.8958\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0402 - acc: 0.9792 - val_loss: 0.3999 - val_acc: 0.9375\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 0.0137 - acc: 0.9948 - val_loss: 0.3591 - val_acc: 0.9167\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0208 - acc: 0.9948 - val_loss: 0.3517 - val_acc: 0.9167\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0561 - acc: 0.9896 - val_loss: 0.3599 - val_acc: 0.8750\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0088 - acc: 0.9948 - val_loss: 0.3598 - val_acc: 0.9167\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3439 - val_acc: 0.9167\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0099 - acc: 0.9948 - val_loss: 0.3503 - val_acc: 0.8958\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0097 - acc: 0.9948 - val_loss: 0.3449 - val_acc: 0.9167\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0321 - acc: 0.9844 - val_loss: 0.3893 - val_acc: 0.9375\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0190 - acc: 0.9948 - val_loss: 0.4118 - val_acc: 0.9167\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.3715 - val_acc: 0.8958\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.3622 - val_acc: 0.8958\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0376 - acc: 0.9844 - val_loss: 0.4077 - val_acc: 0.8958\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0232 - acc: 0.9948 - val_loss: 0.3200 - val_acc: 0.9167\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.3361 - val_acc: 0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8bd1a6fc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlaTgc6Ls_tA",
        "colab_type": "text"
      },
      "source": [
        "Test the accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYXXjZjNpASy",
        "colab_type": "code",
        "outputId": "fb36d931-f22a-4b98-f271-a43c4498e3bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "scores = model.evaluate(test_x, test_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60/60 [==============================] - 0s 2ms/step\n",
            "acc: 91.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiDSg594tIn3",
        "colab_type": "text"
      },
      "source": [
        "Save the model in .h5 format for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHbVi1AYrn-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}